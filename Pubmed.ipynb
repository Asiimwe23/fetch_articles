{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "094a292a-682d-4050-b7b9-b1654418c23b",
   "metadata": {},
   "source": [
    "# Script for downloading articles from PubMEd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c4bcd7-8dc8-4924-bbbc-9a6cb0031263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8637752-6057-48be-95c8-d5632d8ef538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8f665-9403-48e6-8d32-1c45e1a6bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6015851-bc16-4e58-8d55-264387f55f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform a PubMed search\n",
    "def search_pubmed(query, max_results=16000):\n",
    "    print(f\"Searching PubMed with query: {query}\")\n",
    "    url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term={query}&retmax={max_results}&retmode=json\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    print(f\"Found {len(data['esearchresult']['idlist'])} articles\")\n",
    "    return data['esearchresult']['idlist']\n",
    "\n",
    "# Function to fetch details of a PubMed article\n",
    "def fetch_article_details(pmid):\n",
    "    url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=pubmed&id={pmid}&retmode=json\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return data['result'][pmid]\n",
    "\n",
    "# Function to parse the article details and extract required information\n",
    "def parse_article_details(article):\n",
    "    title = article['title']\n",
    "    authors = ', '.join([author['name'] for author in article['authors']])\n",
    "    doi = article.get('elocationid', 'N/A')\n",
    "    abstract_url = f\"https://pubmed.ncbi.nlm.nih.gov/{article['uid']}/\"\n",
    "    abstract_response = requests.get(abstract_url)\n",
    "    abstract_soup = BeautifulSoup(abstract_response.text, 'html.parser')\n",
    "    abstract = abstract_soup.find('div', {'class': 'abstract-content selected'}).text.strip() if abstract_soup.find('div', {'class': 'abstract-content selected'}) else 'N/A'\n",
    "    return {\n",
    "        'Title': title,\n",
    "        'Author': authors,\n",
    "        'DOI': doi,\n",
    "        'Abstract': abstract\n",
    "    }\n",
    "\n",
    "# Text mining functions\n",
    "def extract_research_question(abstract):\n",
    "    sentences = abstract.split('.')\n",
    "    keywords = ['research question', 'study aim', 'objective', 'this study', 'we investigate']\n",
    "    for sentence in sentences:\n",
    "        if any(keyword in sentence.lower() for keyword in keywords):\n",
    "            return sentence.strip()\n",
    "    return 'N/A'\n",
    "\n",
    "def extract_research_gap(abstract):\n",
    "    sentences = abstract.split('.')\n",
    "    keywords = ['however', 'but', 'nevertheless', 'gap', 'challenge', 'unknown']\n",
    "    for sentence in sentences:\n",
    "        if any(keyword in sentence.lower() for keyword in keywords):\n",
    "            return sentence.strip()\n",
    "    return 'N/A'\n",
    "\n",
    "def extract_main_findings(abstract):\n",
    "    sentences = abstract.split('.')\n",
    "    keywords = ['results', 'findings', 'we found', 'our study shows', 'conclusion']\n",
    "    for sentence in sentences:\n",
    "        if any(keyword in sentence.lower() for keyword in keywords):\n",
    "            return sentence.strip()\n",
    "    return 'N/A'\n",
    "\n",
    "# Function to determine if the data is FAIR\n",
    "def is_fair_data(abstract):\n",
    "    return 'Yes' if 'data available' in abstract.lower() or 'open data' in abstract.lower() else 'No'\n",
    "\n",
    "# Function to determine the area of focus\n",
    "def determine_area_of_focus(abstract):\n",
    "    if 'malaria' in abstract.lower():\n",
    "        return 'Malaria'\n",
    "    elif 'hiv' in abstract.lower():\n",
    "        return 'HIV'\n",
    "    elif 'maternal health' in abstract.lower():\n",
    "        return 'Maternal Health'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Function to check if genomic data is available\n",
    "def is_genomic_data_available(abstract):\n",
    "    return 'Yes' if 'genomic' in abstract.lower() else 'No'\n",
    "\n",
    "# Main function to perform the search and generate the CSV file\n",
    "def main():\n",
    "    query = 'health open data kenya malaria hiv maternal mental'\n",
    "    pmids = search_pubmed(query)\n",
    "    articles = []\n",
    "    \n",
    "    for pmid in pmids:\n",
    "        article_details = fetch_article_details(pmid)\n",
    "        parsed_details = parse_article_details(article_details)\n",
    "        parsed_details['FAIR Data'] = is_fair_data(parsed_details['Abstract'])\n",
    "        parsed_details['Area of Focus'] = determine_area_of_focus(parsed_details['Abstract'])\n",
    "        parsed_details['Research Question'] = extract_research_question(parsed_details['Abstract'])\n",
    "        parsed_details['Research Gap'] = extract_research_gap(parsed_details['Abstract'])\n",
    "        parsed_details['Main Findings'] = extract_main_findings(parsed_details['Abstract'])\n",
    "        parsed_details['Genomic Data Available'] = is_genomic_data_available(parsed_details['Abstract'])\n",
    "        articles.append(parsed_details)\n",
    "    \n",
    "    df = pd.DataFrame(articles)\n",
    "    csv_filename = 'health_data_kenya_pubmed_refined.csv'\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Data saved to {csv_filename}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
