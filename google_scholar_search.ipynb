{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f65fd4-3bbc-4a4e-bf44-3d666d8de9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd38efee-4673-42c5-b3a4-7d24f02ab615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92723567-edd5-4ba5-b428-cea11fd5a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f4f6dc9-92e9-4e72-acd9-05e5c5314943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholarly import scholarly\n",
    "from scholarly._navigator import MaxTriesExceededException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c12e7fec-9563-427d-a785-bbb123ea4721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching Google Scholar with query: ((malaria OR falciparum) AND (kelch13 OR Pfkelch13 OR k13 OR PfK13)\n",
      "Retrying in 60 seconds... (1/5)\n",
      "Retrying in 120 seconds... (2/5)\n",
      "Retrying in 240 seconds... (3/5)\n",
      "Retrying in 480 seconds... (4/5)\n",
      "Max tries exceeded. Stopping the search.\n",
      "Found 550 articles\n"
     ]
    }
   ],
   "source": [
    "# Function to search Google Scholar\n",
    "def search_scholar(query, max_results=1000):\n",
    "    print(f\"Searching Google Scholar with query: {query}\")\n",
    "    search_query = scholarly.search_pubs(query)\n",
    "    articles = []\n",
    "    tries = 0\n",
    "    max_tries = 5  # Maximum number of retries\n",
    "\n",
    "    for i in range(max_results):\n",
    "        try:\n",
    "            article = next(search_query)\n",
    "            articles.append(article)\n",
    "            # Adding a delay between 5 and 10 seconds\n",
    "            time.sleep(random.uniform(5, 10))\n",
    "            tries = 0  # Reset tries after a successful fetch\n",
    "        except StopIteration:\n",
    "            break\n",
    "        except MaxTriesExceededException:\n",
    "            tries += 1\n",
    "            if tries >= max_tries:\n",
    "                print(\"Max tries exceeded. Stopping the search.\")\n",
    "                break\n",
    "            wait_time = 60 * (2 ** (tries - 1))  # Exponential backoff\n",
    "            print(f\"Retrying in {wait_time} seconds... ({tries}/{max_tries})\")\n",
    "            time.sleep(wait_time)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "    print(f\"Found {len(articles)} articles\")\n",
    "    return articles\n",
    "\n",
    "# Function to parse the article details and extract required information\n",
    "def parse_article_details(article):\n",
    "    print(f\"Parsing details for article: {article['bib']['title']}\")\n",
    "    title = article['bib']['title']\n",
    "    authors = ', '.join(article['bib']['author'])\n",
    "    doi = article['bib'].get('doi', 'N/A')\n",
    "    abstract = article['bib'].get('abstract', 'N/A')\n",
    "    date = article['bib'].get('year', 'N/A')\n",
    "    return {\n",
    "        'Title': title,\n",
    "        'Author': authors,\n",
    "        'DOI': doi,\n",
    "        'Abstract': abstract\n",
    "    }\n",
    "\n",
    "def extract_main_findings(abstract):\n",
    "    sentences = abstract.split('.')\n",
    "    keywords = ['results', 'findings', 'we found', 'our study shows', 'conclusion']\n",
    "    for sentence in sentences:\n",
    "        if any(keyword in sentence.lower() for keyword in keywords):\n",
    "            return sentence.strip()\n",
    "    return 'N/A'\n",
    "\n",
    "# Main function to perform the search and generate the CSV file\n",
    "def main():\n",
    "    query = '((malaria OR falciparum) AND (kelch13 OR Pfkelch13 OR k13 OR PfK13)' #AND (Kenya OR Uganda OR Ethiopia OR Somalia OR Rwanda OR Tanzania OR Congo OR DRC OR Eritrea OR Sudan OR South Sudan OR Madagascar OR Mozambique OR Comoros OR Djibouti OR Burundi OR Malawi OR Zambia)) AND ((\"2020/01/01\" [Date - Publication]: \"2024/09/24\" [Date - Publication]))'\n",
    "    articles = search_scholar(query, max_results=1000)  # Reduce max_results to avoid rate limits\n",
    "    #parsed_articles = []\n",
    "    \n",
    "    \"\"\"for article in articles:\n",
    "        article_details = parse_article_details(article)\n",
    "        article_details1['Main Findings'] = extract_main_findings(article_details['Abstract'])\n",
    "        parsed_articles.append(article_details)\n",
    "    \n",
    "    df = pd.DataFrame(articles)\n",
    "    csv_filename = 'K13_review_google_scholar.csv'\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Data saved to {csv_filename}\")\"\"\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacd51b5-359f-4482-bd2f-cc69f8882f61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
